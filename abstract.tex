\begin{abstract}
%Modern microprocessors have undergone decades of hardware optimizations.
%For example, modern x86-64 microprocessors employ sophisticated
%instruction execution paths with heavily pipelined,
%out-of-order, super-scalar execution units that are highly complex.
%Producing code that
%exploits and optimizes for this underlying execution environment requires careful
%modelling of the microprocessor functionality. To achieve this, modern compilers employ processor models that predict
%the cost of
%executing a set of instructions to perform backend optimizations such as instruction
%selection, register allocation, instruction scheduling etc.
%\ajay{The lines till here sound a bit repetitive. We are not saying anything concrete here. All we are saying is microprocessors are complex}.
%\ajay{Also, mentioning x86\_64 as an example is a bit misleading. Because we do only for x86\_64. We should start directly with - Modern x86\_64 employs}.
%However, these cost models receive less attention than optimizations themselves.
Modern x86 processors have complex performance characteristics due
to micro-architectural optimizations such as \chcomment{pipelining, super-scalar,} out-of-order executions and micro-op fusions.
To reduce the complexity of optimizing for these processors,
many optimization techniques, manual or automatic, use cost models
to abstract away target machines.
Inaccurate models can cause misoptimizations.
There are known, sometimes significant issues of
cost models in production compilers such as LLVM\cite{llvm} and machine code analyzers
written by processor vendors themselves such as IACA\cite{iaca}.
IACA has been shown in some cases to deviate from the measured throughput
of a basic block of instructions by more than 2x.
Despite this, there is no standard, systematic approach or tooling
to perform validation and tuning of processor cost models.

In this paper, we present the necessary tooling and a benchmark suite
for validating and tuning cost models of x86-64 basic blocks.
Our benchmark suite contains more than 300,000 \chcomment{should have the number for the entire suite}
basic blocks extracted from a wide range of applications.
We describe our throughput profiling tool
that automatically and accurately profiles the throughput
of these basic blocks. \chcomment{Something on how hard measurement is?} We analyze the benchmark suite and show how and where popular
cost models used by static predictors such as llvm-mca, IACA, Ithemal and
OSACA\cite{osaca} deviate from the ground truth measured data.
We show that in certain classes of basic blocks
(e.g. vectorized numerical kernels) even the most accurate
model is on average more than 30\% away from the ground truth.
Furthermore, our dataset can be used as training data for learning-based cost models, such as in Ithemal.

%In addition to cost model validation,
%our dataset and the profiling infrastructure is useful
%for data-driven cost model construction\cite{ithemal}.

%In spite of this, compiler cost models undergo low levels
%of validation and scrutiny due to the lack of tolling and
%test suites that generate validation data.


% Modern super-scalar out-or-order processors are complex objects.
% To reduce the complexity of optimizing for these processors,
% many optimization techniques, manual or automatic, use cost models
% to abstract away target machines.
% Cost models however receive less attentions than optimizations,
% and inaccurate models can cause miss optimizations.
% There are known, sometimes significant issues of
% cost models in production compilers such as LLVM\cite{llvm,goslp}.
% Even IACA, Intel's own throughput predictor has
% been shown in some cases to deviate from measured throughput
% by more than 100\%.

% Despite the importance of existing cost models,
% to this day there is no standard, systematic approach 
% to perform cost model validation and tuning.
% We describe a benchmark for validating performance 
% models of x86 basic blocks.
% Our dataset contains more than three hundred thousand
% basic blocks extracted from a wide range of applications.
% We describe our technique to profile the throughput
% of these basic blocks automatically and accurately.
% We automatically classified our basic blocks by their use
% of CPU resources and evaluated accuracy of existing cost models
% for different classes of basic blocks. 
% We showed that in certain classes of basic blocks 
% (e.g. vectorized numerical kernels) even the most accurate
% model is on average more than 30\% away from the ground truth.
% In addition to cost model validation,
% our dataset and the profiling infrastructure is useful
% for data-driven cost model construction\cite{ithemal}.
\end{abstract}